<HTML>
<body>
<h1>Artificial Intelligence devices page
<h2> Links: <h2>
 <ul>
  <li> <a href="mainbage.html">main bage</a> </li>
  <li> <a href="mainprinciples.html">main principles</a> </li>
  <li><a href="statistics.html">statistic devices</a> </li>
  <li><a href="devices.html">Artificial Intelligence devices</a> </li>
Ethical machines
Machines with intelligence have the potential to use their intelligence to prevent harm and minimize the risks; 
they may have the ability to use ethical reasoning to better choose their actions in the world. 
As such, there is a need for policy making to devise policies for and regulate artificial intelligence and robotics.
[214] Research in this area includes machine ethics, artificial moral agents, 
friendly AI and discussion towards building a human rights framework is also in talks.
[215]Joseph Weizenbaum in Computer Power and Human Reason wrote that AI applications cannot,
 by definition, successfully simulate genuine human empathy and that the use
 of AI technology in fields such as customer service or psychotherapy[j] was deeply misguided.
 Weizenbaum was also bothered that AI researchers  were willing to view the human mind as nothing more than 
 a computer program (a position now known as computationalism).
 To Weizenbaum these points suggest that AI research devalues human life.
 [217]Artificial moral agents
Wendell Wallach introduced the concept of artificial moral agents (AMA) in his book Moral Machines[218] For Wallach,
 AMAs have become a part of the research landscape of artificial intelligence as guided by its two central questions which he identifies
 as "Does Humanity Want Computers Making Moral Decisions"
 [219] and "Can (Ro)bots Really Be Moral".
 [220] For Wallach, the question is not centered on the issue of whether machines can demonstrate the equivalent of moral behavior,
 unlike the constraints which society may place on the development of AMAs.
<h1> Artificial Intelligence main page <h1>
<body>
<HTML>